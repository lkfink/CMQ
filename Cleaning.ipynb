{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pre-process Coronavirus Music Questionnaire (CMQ) data**\n",
    "Lindsay Warrenburg & Lauren Fink  \n",
    "lindsay.a.warrenburg@gmail.com  lauren.fink@ae.mpg.de  \n",
    "Final version: December 20, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this Jupyter Notebook is to clean the data from all different survey versions (languages) in Qualtrics.\n",
    "\n",
    "We have around 1000 survey responses from Germany, Italy, France, India, New York, and the UK. Though the survey questions were almost identical in all versions, there are a few differences that need to be handled. \n",
    "\n",
    "We also need to get all question responses into useable formats and to remove any participants who were not taking the study seriously. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load required packages and modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic coding/ML tools\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import os, sys, scipy, xlrd, urllib, itertools, re, warnings\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns, IPython.display\n",
    "from IPython.display import Image, HTML\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14,4)\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Local imports\n",
    "import local_dicts # dictionary defining column labels for our dataframe and answer text~answer code relationships \n",
    "import local_funcs # functions that we might want to use in multiple scripts throughout the project\n",
    "import importlib\n",
    "\n",
    "importlib.reload(local_dicts) \n",
    "importlib.reload(local_funcs)\n",
    "\n",
    "# display all columns in dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and combine data\n",
    "\n",
    "In this section, we load all the Qualtrics dataframes:\n",
    "1. Prolific data\n",
    "2. Social Media data\n",
    "3. Germany data\n",
    "4. France data\n",
    "5. Italy data\n",
    "6. India data\n",
    "7. US (NY) data \n",
    "\n",
    "We also fix known discrepencies between the different language versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each data frame:\n",
      "\n",
      "Prolific :\t (925, 209)\n",
      "Social Media :\t (406, 209)\n",
      "Ipsos_Germany :\t (1048, 206)\n",
      "Ipsos_France :\t (1094, 218)\n",
      "Ipsos_Italy :\t (1059, 219)\n",
      "Ipsos_India :\t (1191, 215)\n",
      "Ipsos_NY :\t (1131, 217)\n"
     ]
    }
   ],
   "source": [
    "# Read in .csv files for each country\n",
    "prolific = pd.read_csv('Raw_Data/prolific.csv')\n",
    "social = pd.read_csv('Raw_Data/social.csv')\n",
    "ger = pd.read_csv('Raw_Data/german.csv')\n",
    "fra = pd.read_csv('Raw_Data/french.csv')\n",
    "ita = pd.read_csv('Raw_Data/italian.csv')\n",
    "ind = pd.read_csv('Raw_Data/indian.csv')\n",
    "ny = pd.read_csv('Raw_Data/ny.csv')\n",
    "\n",
    "# Add column to each datafram about source (for when we concatenate them later)\n",
    "prolific['Survey Info_Source'] = 'Prolific'\n",
    "social['Survey Info_Source'] = 'Social Media'\n",
    "ger['Survey Info_Source'] = 'Ipsos_Germany'\n",
    "fra['Survey Info_Source'] = 'Ipsos_France'\n",
    "ita['Survey Info_Source'] = 'Ipsos_Italy'\n",
    "ind['Survey Info_Source'] = 'Ipsos_India'\n",
    "ny['Survey Info_Source'] = 'Ipsos_NY'\n",
    "\n",
    "# For all of the Ipsos frames, remove data from people that were screened out \n",
    "# or kicked out because a quota was full\n",
    "def cleanIpsos(df):\n",
    "    nd = df.loc[df['Q_TerminateFlag'].astype(str) != 'Screened']\n",
    "    nd = nd.loc[nd['Q_TerminateFlag'].astype(str) != 'QuotaMet']\n",
    "    return nd\n",
    "\n",
    "ger = cleanIpsos(ger)\n",
    "fra = cleanIpsos(fra)\n",
    "ita = cleanIpsos(ita)\n",
    "ind = cleanIpsos(ind)\n",
    "ny = cleanIpsos(ny)\n",
    "\n",
    "# Fix column name issues specific to certain contries \n",
    "ny.rename(columns={'8c': '8c_state', '8c.1': '8c'}, inplace=True, errors=\"raise\") # this aligns 8c to be ESM MIDDLE, like in other surveys\n",
    "\n",
    "#ger.rename(columns={'33_3': '33_7', '33_4': '33_6', '33_5': '33_4', '33_6':'33_5', '33_7':'33_3'}, inplace=True, errors=\"raise\")\n",
    "#fra.rename(columns={'23_2': '23_3', '23_3': '23_2'}, inplace=True, errors=\"raise\")\n",
    "# TODO CHECK - does it do all at once because if not, we are re-writing duplicate columns\n",
    "# do it serially to be safe\n",
    "ger.rename(columns={'33_3': '33_7new', '33_4': '33_6new', '33_5': '33_4new', '33_6':'33_5new', '33_7':'33_3new'}, inplace=True, errors=\"raise\")\n",
    "ger.rename(columns={'33_7new':'33_7', '33_6new':'33_6', '33_4new':'33_4', '33_5new':'33_5', '33_3new':'33_3'}, inplace=True, errors=\"raise\")\n",
    "\n",
    "fra.rename(columns={'23_2': '23_3_new', '23_3': '23_2_new'}, inplace=True, errors=\"raise\")\n",
    "fra.rename(columns={'23_3_new':'23_3', '23_2_new':'23_2'}, inplace=True, errors=\"raise\")\n",
    "\n",
    "# Translate answer code values into years in school for prolific and social surveys. \n",
    "# (for other surveys this was numeric free response)\n",
    "# In all other surveys, these were free numeric input\n",
    "prolific['3'].iloc[2:] = prolific['3'].iloc[2:].astype(float).map(local_dicts.prolific_school_dict, na_action='ignore')\n",
    "prolific['4'].iloc[2:] = prolific['4'].iloc[2:].astype(float).map(local_dicts.prolific_post_school_dict, na_action='ignore')\n",
    "social['3'].iloc[2:] = social['3'].iloc[2:].astype(float).map(local_dicts.prolific_school_dict, na_action='ignore')\n",
    "social['4'].iloc[2:] = social['4'].iloc[2:].astype(float).map(local_dicts.prolific_post_school_dict, na_action='ignore') \n",
    "\n",
    "# Fix issue of French version having different answer coding for Q 33\n",
    "fix = [col for col in fra.columns if '33_' in col]\n",
    "for i in fix:\n",
    "    fra[i].iloc[2:] = fra[i].iloc[2:].map(local_dicts.french_Q33_dict, na_action='ignore')\n",
    "    \n",
    "# Fix issue of France and Italy having different gender orders\n",
    "# this is question 2\n",
    "fra['2'].iloc[2:] = fra['2'].iloc[2:].map(local_dicts.frenchItal_gender_dict, na_action='ignore')\n",
    "ita['2'].iloc[2:] = ita['2'].iloc[2:].map(local_dicts.frenchItal_gender_dict, na_action='ignore')\n",
    "\n",
    "# Fix issue of France and German having different answer codes for listening to music differently question\n",
    "# this is question 16\n",
    "fra['16'].iloc[2:] = fra['16'].iloc[2:].map(local_dicts.frenchGer_YN_musDiff_dict, na_action='ignore')\n",
    "ger['16'].iloc[2:] = ger['16'].iloc[2:].map(local_dicts.frenchGer_YN_musDiff_dict, na_action='ignore')\n",
    "    \n",
    "# Print size of each data set\n",
    "print(\"Size of each data frame:\\n\")\n",
    "frames = [prolific, social, ger, fra, ita, ind, ny]\n",
    "for df in frames: \n",
    "    print(df['Survey Info_Source'].iloc[0],':\\t', df.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value tells us the number of rows (i.e participants). The second value tells us the number of columns. Some of the extra columns in the different datasets are survey meta data that we do not need. Let's take a look at the column names. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that column names are the same between countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment below if want to see column names \n",
    "# print(list(fra.columns))\n",
    "# print('\\n\\n')\n",
    "# print(list(prolific.columns))\n",
    "\n",
    "# print(fra['ResponseId'].head(5))\n",
    "### NOTE: Will used response ID in his cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it is clear that we can use the column names as keys to concatenate all of the datasets. We will then deal with deleting irrelevant columns. See key-value mappings in 'local_dicts.py'\n",
    "\n",
    "### Concatenate data frames from each source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use outerjoin to combine all tables.\n",
    "# Outerjoin allows us to keep all columns and add NAs for missing columns in the other datasets\n",
    "data = pd.concat(frames, axis=0, join='outer', sort=False)\n",
    "\n",
    "### Uncomment below, if want to have a look at newly combined data frame\n",
    "# print(data.shape)\n",
    "# print('\\n\\n')\n",
    "# print(data.head(5))\n",
    "# print('\\n\\n')\n",
    "# print(list(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns to have meaningful labels\n",
    "Here, we rename the columns according to the survey questions, as defined in our imported dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 206)\n"
     ]
    }
   ],
   "source": [
    "# drop columns we no longer need\n",
    "data = data.drop(columns=local_dicts.dropCols)\n",
    "\n",
    "# rename columns according to our column dictionary\n",
    "data.rename(columns=local_dicts.column_dict, inplace=True)\n",
    "\n",
    "# print(list(data.columns))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up column types and labels\n",
    "- Remove the first two rows of data, which correspond to the instructions.\n",
    "- Write the instructions to a file for future use. \n",
    "- Remove any participants who got sent to the end of the survey because they were < 18\n",
    "- Rearrange the columns to be in alphabetical order -- this way all the ***Music Listening*** columns are together and all the ***Making Music*** columns are together, etc.\n",
    "- Convert numeric columns to numeric.\n",
    "- Recode specific columns\n",
    "- Remove any participants under 18 that got sent to end of survey\n",
    "- Examine data type of our dataframe columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove first two rows (instructions)   \n",
    "instructions = data.iloc[0,:] # keep these in case we want to look at question text later\n",
    "instructions.to_csv(r'instructions.csv', index = None, header = True) # write to .csv\n",
    "data = data.drop([0, 1])\n",
    "\n",
    "# Convert all numeric columns to numeric. Exclude open and one hot columns\n",
    "num_cols = []\n",
    "for key, val in local_dicts.answer_code_dict.items(): \n",
    "    if val != 'open' and key not in local_dicts.oneHotCols:\n",
    "        num_cols.append(key)\n",
    "          \n",
    "# Convert numeric      \n",
    "data[num_cols] = data[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Remove people < 18 from non-Ipsos data\n",
    "# (there was no screen out flag for that), even though they got kicked to the last page\n",
    "data = data.loc[data['Demographics_General_Age'] >= 18]\n",
    "\n",
    "# Recode Ollen to be on proper scale (start at 1 instead of 0)\n",
    "data['Demographics_Music_Ollen'] = data['Demographics_Music_Ollen'] + 1\n",
    "\n",
    "# Recode number of times leaving house\n",
    "# This question starts with the answer 0 with code 1, so we need to subtract 1 from the column to get in actual values\n",
    "data[\"Demographics_COVID_Number Times Leave\"] = data['Demographics_COVID_Number Times Leave'] - 1\n",
    "\n",
    "# Turn survey duration into minutes (from seconds)\n",
    "data[\"Survey Info_Duration\"] = data['Survey Info_Duration'].astype(float)/60\n",
    "\n",
    "# Re-index\n",
    "data.reset_index(inplace = True, drop = True) \n",
    "\n",
    "# Rearrange columns to be in alphabetical order\n",
    "data = data.reindex(sorted(data.columns), axis=1)\n",
    "\n",
    "### column types\n",
    "# local_funcs.View(data.dtypes.to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate unique codes for ESM study\n",
    "We need to keep track of each person's self-generated ESM code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm = [col for col in data.columns if col.startswith('ESM_')]\n",
    "esm.remove('ESM_ID') # don't touch the Qualtrics ID\n",
    "\n",
    "# Clean text in ESM cols\n",
    "for col in esm:\n",
    "    data[col] = data[col].str.strip()\n",
    "    data[col] = data[col].str.upper()\n",
    "    \n",
    "# Combine code into one ESM code\n",
    "data['ESM_Self-Generated Code'] = data['ESM_Mother'] + data['ESM_Father'] + data['ESM_Middle'] + data['ESM_Town']\n",
    "\n",
    "# Drop the other columns we no longer need\n",
    "data = data.drop(['ESM_Mother', 'ESM_Father', 'ESM_Middle', 'ESM_Town'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Free Responses\n",
    "First, look at the raw responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "free = [col for col in data.columns if col.endswith('Free Response')]\n",
    "# for column in free:\n",
    "#     print(\"Column:\", column)\n",
    "#     print(data[column].unique())\n",
    "#     print(\"\\n \\n---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in free: \n",
    "    local_funcs.textCleaning(data, column)\n",
    "#     print(\"Column:\", column, \"\\n\")\n",
    "#     print(data[column].unique())\n",
    "#     print(\"\\n \\n---------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one write-in response (`Profession`) that we can clean a bit, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics_COVID_Profession\n",
    "data['Demographics_COVID_Profession'] = data['Demographics_COVID_Profession'].str.strip()\n",
    "data['Demographics_COVID_Profession'] = data['Demographics_COVID_Profession'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create One-Hot Encoded Columns\n",
    "When you have a survey question that allows you to pick several options (like a `Check all that apply` question), you get some answers with only one \"checked\" item and other answers with many \"checked\" items. It's impossible to analyze responses this way.\n",
    "\n",
    "**Instead, we need to create separate columns for each possible item. For example\"**\n",
    "- For the `Living Situation` questions, a person may respond `I live with a pet` and `I live with a child.` \n",
    "- We should create a *Yes/No* column for `I live with a pet` and `I live with a child.`\n",
    "- Some people will have many items checked (multiple \"yes\" responses), whereas others will have no items or 1 item selected.\n",
    "- I also created a `No Response` column to distinguish those who left the question blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics_COVID_Living Situation \n",
    "# recode cousin to 0\n",
    "data['Demographics_COVID_Living Situation'] = data['Demographics_COVID_Living Situation'].str.replace('10','0')\n",
    "\n",
    "data['Demographics_COVID_Living Situation-Alone'] = np.where(data['Demographics_COVID_Living Situation'].str.contains('1', na=False), 1, 0)\n",
    "data['Demographics_COVID_Living Situation-Pet'] = np.where(data['Demographics_COVID_Living Situation'].str.contains('2', na=False), 1, 0)\n",
    "data['Demographics_COVID_Living Situation-Partner'] = np.where(data['Demographics_COVID_Living Situation'].str.contains('3', na=False), 1, 0)\n",
    "data['Demographics_COVID_Living Situation-Child'] = np.where(data['Demographics_COVID_Living Situation'].str.contains('4', na=False), 1, 0)\n",
    "data['Demographics_COVID_Living Situation-Parent'] = np.where(data['Demographics_COVID_Living Situation'].str.contains('5', na=False), 1, 0)\n",
    "data['Demographics_COVID_Living Situation-Elderly'] = np.where(data['Demographics_COVID_Living Situation'].str.contains('6', na=False), 1, 0)\n",
    "data['Demographics_COVID_Living Situation-Friend'] = np.where(data['Demographics_COVID_Living Situation'].str.contains('7', na=False), 1, 0)\n",
    "data['Demographics_COVID_Living Situation-Shared'] = np.where(data['Demographics_COVID_Living Situation'].str.contains('8', na=False), 1, 0)\n",
    "data['Demographics_COVID_Living Situation-Other'] = np.where(data['Demographics_COVID_Living Situation'].str.contains('9', na=False), 1, 0)\n",
    "data['Demographics_COVID_Living Situation-SibCous'] = np.where(data['Demographics_COVID_Living Situation'].str.contains('0', na=False), 1, 0)\n",
    "data['Demographics_COVID_Living Situation-No Response'] = pd.isnull(data['Demographics_COVID_Living Situation']) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the original column *Demographics_COVID_Living Situation* with the new *Yes/No* columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[:, ['Demographics_COVID_Living Situation',\n",
    "#              'Demographics_COVID_Living Situation-Alone',\n",
    "#              'Demographics_COVID_Living Situation-Pet',\n",
    "#              'Demographics_COVID_Living Situation-Partner',\n",
    "#              'Demographics_COVID_Living Situation-Child',\n",
    "#              'Demographics_COVID_Living Situation-Parent',\n",
    "#              'Demographics_COVID_Living Situation-Elderly',\n",
    "#              'Demographics_COVID_Living Situation-Friend',\n",
    "#              'Demographics_COVID_Living Situation-Shared',\n",
    "#              'Demographics_COVID_Living Situation-Other',\n",
    "#              'Demographics_COVID_Living Situation-SibCous',\n",
    "#              'Demographics_COVID_Living Situation-No Response']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now repeat this process for other questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics_COVID_Ways Work Affected\n",
    "data['Demographics_COVID_Ways Work Affected-Still Go To Work'] = np.where(data['Demographics_COVID_Ways Work Affected'].str.contains('1', na=False), 1, 0)\n",
    "data['Demographics_COVID_Ways Work Affected-Still Work From Home'] = np.where(data['Demographics_COVID_Ways Work Affected'].str.contains('2', na=False), 1, 0)\n",
    "data['Demographics_COVID_Ways Work Affected-Now Work From Home'] = np.where(data['Demographics_COVID_Ways Work Affected'].str.contains('3', na=False), 1, 0)\n",
    "data['Demographics_COVID_Ways Work Affected-Reduced Hours'] = np.where(data['Demographics_COVID_Ways Work Affected'].str.contains('4', na=False), 1, 0)\n",
    "data['Demographics_COVID_Ways Work Affected-Lower Income'] = np.where(data['Demographics_COVID_Ways Work Affected'].str.contains('5', na=False), 1, 0)\n",
    "data['Demographics_COVID_Ways Work Affected-Lost Job'] = np.where(data['Demographics_COVID_Ways Work Affected'].str.contains('6', na=False), 1, 0)\n",
    "data['Demographics_COVID_Ways Work Affected-Job At Risk'] = np.where(data['Demographics_COVID_Ways Work Affected'].str.contains('7', na=False), 1, 0)\n",
    "data['Demographics_COVID_Ways Work Affected-Homeschool Children'] = np.where(data['Demographics_COVID_Ways Work Affected'].str.contains('8', na=False), 1, 0)\n",
    "data['Demographics_COVID_Ways Work Affected-No Response'] = pd.isnull(data['Demographics_COVID_Ways Work Affected']) * 1\n",
    "\n",
    "# data.loc[:, ['Demographics_COVID_Ways Work Affected',\n",
    "#              'Demographics_COVID_Ways Work Affected-Still Go To Work',\n",
    "#              'Demographics_COVID_Ways Work Affected-Still Work From Home',\n",
    "#              'Demographics_COVID_Ways Work Affected-Now Work From Home',\n",
    "#              'Demographics_COVID_Ways Work Affected-Reduced Hours',\n",
    "#              'Demographics_COVID_Ways Work Affected-Lower Income',\n",
    "#              'Demographics_COVID_Ways Work Affected-Lost Job',\n",
    "#              'Demographics_COVID_Ways Work Affected-Job At Risk',\n",
    "#              'Demographics_COVID_Ways Work Affected-Homeschool Children',\n",
    "#              'Demographics_COVID_Ways Work Affected-No Response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics_Health_Infected with COVID\n",
    "data['Demographics_Health_Infected with COVID-I Am Infected'] = np.where(data['Demographics_Health_Infected with COVID'].str.contains('1', na=False), 1, 0)\n",
    "data['Demographics_Health_Infected with COVID-I Live With Someone'] = np.where(data['Demographics_Health_Infected with COVID'].str.contains('2', na=False), 1, 0)\n",
    "data['Demographics_Health_Infected with COVID-I Have Professional Contact'] = np.where(data['Demographics_Health_Infected with COVID'].str.contains('3', na=False), 1, 0)\n",
    "data['Demographics_Health_Infected with COVID-Someone I Am Close To'] = np.where(data['Demographics_Health_Infected with COVID'].str.contains('4', na=False), 1, 0)\n",
    "data['Demographics_Health_Infected with COVID-I Am Mourning A Loss'] = np.where(data['Demographics_Health_Infected with COVID'].str.contains('5', na=False), 1, 0)\n",
    "data['Demographics_Health_Infected with COVID-None'] = np.where(data['Demographics_Health_Infected with COVID'].str.contains('0', na=False), 1, 0)\n",
    "data['Demographics_Health_Infected with COVID-Prefer Not To Say'] = np.where(data['Demographics_Health_Infected with COVID'].str.contains('99', na=False), 1, 0)\n",
    "data['Demographics_Health_Infected with COVID-No Response'] = pd.isnull(data['Demographics_Health_Infected with COVID']) * 1\n",
    "\n",
    "# data.loc[:, ['Demographics_Health_Infected with COVID',\n",
    "#              'Demographics_Health_Infected with COVID-I Am Infected',\n",
    "#              'Demographics_Health_Infected with COVID-I Live With Someone',\n",
    "#              'Demographics_Health_Infected with COVID-I Have Professional Contact',\n",
    "#              'Demographics_Health_Infected with COVID-Someone I Am Close To',\n",
    "#              'Demographics_Health_Infected with COVID-I Am Mourning A Loss',\n",
    "#              'Demographics_Health_Infected with COVID-Prefer Not To Say',\n",
    "#              'Demographics_Health_Infected with COVID-No Response']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since we have the one-hot encoded columns now, we can delete the original columns with text responses.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape:  (6677, 228)\n"
     ]
    }
   ],
   "source": [
    "# drop fixed multi-choice columns\n",
    "data = data.drop(['Demographics_COVID_Living Situation', \n",
    "                  'Demographics_COVID_Ways Work Affected',\n",
    "                  'Demographics_Health_Infected with COVID'], \n",
    "                 axis=1)\n",
    "\n",
    "print(\"data.shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE employment before covid\n",
    "data['Demographics_General_Employement Before COVID-Employed Full Time'] = np.where(data['Demographics_COVID_Employement Before COVID'] == 4, 1, 0)\n",
    "data['Demographics_General_Employement Before COVID-Employed Part Time'] = np.where(data['Demographics_COVID_Employement Before COVID'] == 5, 1, 0)\n",
    "data['Demographics_General_Employement Before COVID-Self Employed'] = np.where(data['Demographics_COVID_Employement Before COVID'] == 6, 1, 0)\n",
    "data['Demographics_General_Employement Before COVID-Student'] = np.where(data['Demographics_COVID_Employement Before COVID'] == 7, 1, 0)\n",
    "data['Demographics_General_Employement Before COVID-Home Maker Caregiver'] = np.where(data['Demographics_COVID_Employement Before COVID'] == 8, 1, 0)\n",
    "data['Demographics_General_Employement Before COVID-Retired'] = np.where(data['Demographics_COVID_Employement Before COVID'] == 10, 1, 0)\n",
    "data['Demographics_General_Employement Before COVID-Prefer Not To Say'] = np.where(data['Demographics_COVID_Employement Before COVID'] == 11, 1, 0)\n",
    "data['Demographics_General_Employement Before COVID-No Response'] = pd.isnull(data['Demographics_COVID_Employement Before COVID']) * 1\n",
    "\n",
    "data = data.drop(['Demographics_COVID_Employement Before COVID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE Generally make music alone or together\n",
    "data['Demographics_Music_Making Music-Alone'] = np.where(data['Demographics_Music_Make Music Alone or Together'] == 1, 1, 0)\n",
    "data['Demographics_Music_Making Music-Together'] = np.where(data['Demographics_Music_Make Music Alone or Together'] == 2, 1, 0)\n",
    "data['Demographics_Music_Making Music-Both Alone And Together'] = np.where(data['Demographics_Music_Make Music Alone or Together'] == 3, 1, 0)\n",
    "data['Demographics_Music_Making Music-No Response'] = pd.isnull(data['Demographics_Music_Make Music Alone or Together']) * 1\n",
    "\n",
    "data = data.drop(['Demographics_Music_Make Music Alone or Together'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE current city type \n",
    "data['Demographics_General_City Type-Rural'] = np.where(data['Demographics_COVID_Current City Type'] == 4, 1, 0)\n",
    "data['Demographics_General_City Type-Suburban'] = np.where(data['Demographics_COVID_Current City Type'] == 5, 1, 0)\n",
    "data['Demographics_General_City Type-Urban'] = np.where(data['Demographics_COVID_Current City Type'] == 6, 1, 0)\n",
    "data['Demographics_General_City Type-No Response'] = pd.isnull(data['Demographics_COVID_Current City Type']) * 1\n",
    "\n",
    "data = data.drop(['Demographics_COVID_Current City Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE type of music listened to during covid\n",
    "data['Music Engagement_Music Types-Same Musicians Composers'] = np.where(data['Music Engagement_Engaging With Music Differently List'] == 11, 1, 0)\n",
    "data['Music Engagement_Music Types-Other Musicians Composers'] = np.where(data['Music Engagement_Engaging With Music Differently List'] == 12, 1, 0)\n",
    "data['Music Engagement_Music Types-Other Genres'] = np.where(data['Music Engagement_Engaging With Music Differently List'] == 13, 1, 0)\n",
    "data['Music Engagement_Music Types-No Response'] = pd.isnull(data['Music Engagement_Engaging With Music Differently List']) * 1\n",
    "\n",
    "data = data.drop(['Music Engagement_Engaging With Music Differently List'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding summary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column for total years of education \n",
    "data['Demographics_General_Education Years'] = data['Demographics_General_Years of School'].fillna(0) + data['Demographics_General_Years of Post-School'].fillna(0)\n",
    "\n",
    "\n",
    "# Create column for covid contact of any kind\n",
    "data['Demographics_Health_COVID Contact Binary'] = 0\n",
    "data['Demographics_Health_COVID Contact Binary'] = np.where( (data['Demographics_Health_Infected with COVID-I Am Infected']==1)\n",
    "                                                            | (data['Demographics_Health_Infected with COVID-I Live With Someone']==1) \n",
    "                                                            | (data['Demographics_Health_Infected with COVID-I Have Professional Contact']==1)\n",
    "                                                            | (data['Demographics_Health_Infected with COVID-Someone I Am Close To']==1)\n",
    "                                                            | (data['Demographics_Health_Infected with COVID-I Am Mourning A Loss']==1), \n",
    "                                                            1, data['Demographics_Health_COVID Contact Binary'])\n",
    "\n",
    "# Create column for general change in work situation\n",
    "data['Demographics_COVID_Work Changed Binary'] = 0\n",
    "data['Demographics_COVID_Work Changed Binary'] = np.where( (data['Demographics_COVID_Ways Work Affected-Now Work From Home']==1) \n",
    "                                                          | (data['Demographics_COVID_Ways Work Affected-Reduced Hours']==1) \n",
    "                                                          | (data['Demographics_COVID_Ways Work Affected-Job At Risk']==1)\n",
    "                                                          | (data['Demographics_COVID_Ways Work Affected-Lower Income']==1)\n",
    "                                                          | (data['Demographics_COVID_Ways Work Affected-Lost Job']==1), \n",
    "                                                          1, data['Demographics_COVID_Work Changed Binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Big 5 Personality Dimensions\n",
    "Here, we recode ten questions from the **10-item Big 5 Personality Questionnaire** into their five components:\n",
    "- Extraversion\n",
    "- Aggreeableness\n",
    "- Conscientiousness\n",
    "- Neuroticism\n",
    "- Openness to experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reverse dictionary for items that need to be reverse scored. \n",
    "reverse_dict = {\"1.0\":7, \"2.0\":6, \"3.0\":5, \"4.0\":4, \"5.0\":3, \"6.0\":2, \"7.0\":1}\n",
    "\n",
    "# Extraversion = Demographics_Personality_Outgoing + Demographics_Personality_Reserved -- REVERSE SCORED\n",
    "data['Demographics_Personality_Reserved_rs'] = data['Demographics_Personality_Reserved'].map(str).map(reverse_dict)\n",
    "data['Demographics_Personality_Extraversion'] = data[['Demographics_Personality_Outgoing', 'Demographics_Personality_Reserved_rs']].mean(axis=1)\n",
    "\n",
    "# # Agreeableness = Demographics_Personality_Trusting + Demographics_Personality_Faults Others -- REVERSE SCORED\n",
    "data['Demographics_Personality_Faults Others_rs'] = data['Demographics_Personality_Faults Others'].map(str).map(reverse_dict)\n",
    "data['Demographics_Personality_Agreeableness'] = data[['Demographics_Personality_Trusting', 'Demographics_Personality_Faults Others_rs']].mean(axis=1)\n",
    "\n",
    "# # Conscientiousness = Demographics_Personality_Thorough + Demographics_Personality_Lazy -- REVERSE SCORED\n",
    "data['Demographics_Personality_Lazy_rs'] = data['Demographics_Personality_Lazy'].map(str).map(reverse_dict)\n",
    "data['Demographics_Personality_Conscientiousness'] = data[['Demographics_Personality_Thorough', 'Demographics_Personality_Lazy_rs']].mean(axis=1)\n",
    "\n",
    "# # Neuroticism = Demographics_Personality_Nervous + Demographics_Personality_Relaxed -- REVERSE SCORED\n",
    "data['Demographics_Personality_Relaxed_rs'] = data['Demographics_Personality_Relaxed'].map(str).map(reverse_dict)\n",
    "data['Demographics_Personality_Neuroticism'] = data[['Demographics_Personality_Nervous', 'Demographics_Personality_Relaxed_rs']].mean(axis=1)\n",
    "\n",
    "# # Openness to experience = Demographics_Personality_Imaginative + Demographics_Personality_Few Artistic Interests -- REVERSE SCORED\n",
    "data['Demographics_Personality_Few Artistic Interests_rs'] = data['Demographics_Personality_Few Artistic Interests'].map(str).map(reverse_dict)\n",
    "data['Demographics_Personality_Openness'] = data[['Demographics_Personality_Imaginative', 'Demographics_Personality_Few Artistic Interests_rs']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it worked. I made a table where the new dimension (e.g., Extraversion) is followed by the two corresponding questions from the questionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[:, ['Demographics_Personality_Extraversion',\n",
    "#              'Demographics_Personality_Outgoing',\n",
    "#              'Demographics_Personality_Reserved_rs',\n",
    "             \n",
    "#              'Demographics_Personality_Agreeableness',\n",
    "#              'Demographics_Personality_Trusting',\n",
    "#              'Demographics_Personality_Faults Others_rs',\n",
    "             \n",
    "#              'Demographics_Personality_Conscientiousness',\n",
    "#              'Demographics_Personality_Thorough',\n",
    "#              'Demographics_Personality_Lazy_rs',\n",
    "            \n",
    "#              'Demographics_Personality_Neuroticism',\n",
    "#              'Demographics_Personality_Nervous',\n",
    "#              'Demographics_Personality_Relaxed_rs',\n",
    "            \n",
    "#              'Demographics_Personality_Openness',\n",
    "#              'Demographics_Personality_Imaginative',\n",
    "#              'Demographics_Personality_Few Artistic Interests_rs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have created columns for the five personality dimensions, we can remove each of the individual questions from our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape:  (6677, 242)\n"
     ]
    }
   ],
   "source": [
    "# drop personality\n",
    "data = data.drop(['Demographics_Personality_Outgoing', 'Demographics_Personality_Reserved', \n",
    "                  'Demographics_Personality_Trusting', 'Demographics_Personality_Faults Others',\n",
    "                  'Demographics_Personality_Thorough', 'Demographics_Personality_Lazy',\n",
    "                  'Demographics_Personality_Nervous', 'Demographics_Personality_Relaxed',\n",
    "                  'Demographics_Personality_Imaginative', 'Demographics_Personality_Few Artistic Interests',\n",
    "                  'Demographics_Personality_Few Artistic Interests_rs', 'Demographics_Personality_Relaxed_rs',  \n",
    "                  'Demographics_Personality_Lazy_rs', 'Demographics_Personality_Faults Others_rs', \n",
    "                  'Demographics_Personality_Reserved_rs'\n",
    "                 ], \n",
    "                 axis=1)\n",
    "\n",
    "print(\"data.shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country-specific cleaning\n",
    "\n",
    "### Remove data not from 6 countries of interest\n",
    "Remove data from countries for which we don't have enough samples\n",
    "Only proceed with subsamples for which we have enough data and which were sampled in an unbiased way. (i.e remove social media sample and remove people in the prolific sample coming from countries outside of UK). We decided as a group that we wanted to save the social media dataset for a different paper and only use data from representative samples for this paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep data from big 6 countries and representative samples \n",
    "# Filter by source, country code, and state code (if relevant)\n",
    "# output individual tables for each country, as well as one concatenated table\n",
    "ger = data.loc[data['Survey Info_Source'] == 'Ipsos_Germany']\n",
    "ger = ger.loc[ger['Demographics_COVID_Current Country'] == 3418]\n",
    "\n",
    "fra = data.loc[data['Survey Info_Source'] == 'Ipsos_France']\n",
    "fra = fra.loc[fra['Demographics_COVID_Current Country'] == 3414]\n",
    "\n",
    "ita = data.loc[data['Survey Info_Source'] == 'Ipsos_Italy']\n",
    "ita = ita.loc[ita['Demographics_COVID_Current Country'] == 3436]\n",
    "\n",
    "ind = data.loc[data['Survey Info_Source'] == 'Ipsos_India']\n",
    "ind = ind.loc[ind['Demographics_COVID_Current Country'] == 3430]\n",
    "\n",
    "ny = data.loc[data['Survey Info_Source'] == 'Ipsos_NY']\n",
    "ny = ny.loc[ny['Demographics_COVID_Current Country'] == 3537]\n",
    "ny = ny.loc[ny['Demographics_COVID_Current State'] == '33']\n",
    "\n",
    "uk = data.loc[data['Survey Info_Source'] == 'Prolific']\n",
    "uk = uk.loc[uk['Demographics_COVID_Current Country'] == 3535]\n",
    "\n",
    "frames = [ger, fra, ita, ind, ny, uk]\n",
    "\n",
    "    \n",
    "# concatenate all into one df again\n",
    "b6 = pd.concat(frames, axis=0, join='outer', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3418. 3414. 3436. 3430. 3537. 3535.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey Info_Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ipsos_India</th>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ipsos_France</th>\n",
       "      <td>1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ipsos_NY</th>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ipsos_Italy</th>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ipsos_Germany</th>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prolific</th>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Survey Info_Source\n",
       "Ipsos_India                  1098\n",
       "Ipsos_France                 1059\n",
       "Ipsos_NY                     1043\n",
       "Ipsos_Italy                  1029\n",
       "Ipsos_Germany                1024\n",
       "Prolific                      654"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b6['Demographics_COVID_Current Country'].unique())\n",
    "pd.DataFrame(b6['Survey Info_Source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5907, 242)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overwrite our data variable before proceeding\n",
    "data = b6.copy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add government indices for each of our 6 countries\n",
    "The Oxford group was tracking government responses to the pandemic situation and has made their data freely available. We are interested in related our survey responses to the severity of lockdown measures in place at the time in each country.\n",
    "\n",
    "More info about the OxCGRT:\n",
    "https://github.com/OxCGRT/covid-policy-tracker/blob/master/documentation/index_methodology.md\n",
    "\n",
    "https://www.bsg.ox.ac.uk/research/research-projects/coronavirus-government-response-tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "og = pd.read_csv('OxCGRT_latest_23062020.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Germany' 'France' 'United Kingdom' 'India' 'Italy' 'United States']\n",
      "Index(['CountryName', 'Date', 'C1_School closing', 'C2_Workplace closing',\n",
      "       'C3_Cancel public events', 'C4_Restrictions on gatherings',\n",
      "       'C5_Close public transport', 'C6_Stay at home requirements',\n",
      "       'C7_Restrictions on internal movement',\n",
      "       'C8_International travel controls', 'E1_Income support',\n",
      "       'E2_Debt/contract relief', 'E3_Fiscal measures',\n",
      "       'E4_International support', 'H1_Public information campaigns',\n",
      "       'H2_Testing policy', 'H3_Contact tracing',\n",
      "       'H4_Emergency investment in healthcare', 'H5_Investment in vaccines',\n",
      "       'ConfirmedCases', 'ConfirmedDeaths', 'StringencyIndex',\n",
      "       'StringencyIndexForDisplay', 'StringencyLegacyIndexForDisplay',\n",
      "       'GovernmentResponseIndex', 'GovernmentResponseIndexForDisplay',\n",
      "       'ContainmentHealthIndex', 'ContainmentHealthIndexForDisplay',\n",
      "       'EconomicSupportIndex', 'EconomicSupportIndexForDisplay'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Explore and clean OG a bit\n",
    "# print(og.columns)\n",
    "\n",
    "# Subset OG to only have data from our countries of interest\n",
    "og = og[og['CountryName'].isin(['Germany', 'Italy', 'France', 'India', 'United Kingdom', 'United States']) ]\n",
    "print(og['CountryName'].unique())\n",
    "\n",
    "# Drop columns we don't need\n",
    "for c in og.columns:\n",
    "    if 'Flag' in c: \n",
    "        og = og.drop(columns = c)\n",
    "#     if 'ForDisplay' in c: # display might actually be what we want because it smoothes over 7 days\n",
    "#         og = og.drop(columns = c)\n",
    "og = og.drop(columns = ['CountryCode', 'M1_Wildcard', 'StringencyLegacyIndex'])        \n",
    "        \n",
    "print(og.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make date reporting formats compatible between the two tables because we need to join based on date. \n",
    "# We will use the end date for our survey responses\n",
    "colName = data.columns.get_loc('Survey Info_EndDate')\n",
    "data.iloc[:,colName] = data.iloc[:,colName].str.split(None, 1)\n",
    "data.iloc[:,colName] = data.iloc[:,colName].map(lambda x: x[0])\n",
    "data.iloc[:,colName] = data.iloc[:,colName].str.replace(\"-\", \"\")\n",
    "data['Survey Info_EndDate'] = data['Survey Info_EndDate'].astype(int)\n",
    "\n",
    "# print(data['Survey Info_EndDate'].head(5))\n",
    "# print(og['Date'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Germany' 'France' 'Italy' 'India' 'USA' 'UK']\n",
      "['Germany' 'France' 'United Kingdom' 'India' 'Italy' 'United States']\n",
      "['Germany' 'France' 'Italy' 'India' 'USA' 'UK']\n",
      "['Germany' 'France' 'UK' 'India' 'Italy' 'USA']\n"
     ]
    }
   ],
   "source": [
    "# Make country labels compatible between the two data frames\n",
    "data['Demographics_COVID_Current Country'] = data['Demographics_COVID_Current Country'].map(local_dicts.answer_code_dict['Demographics_COVID_Current Country'])\n",
    "print(data['Demographics_COVID_Current Country'].unique())\n",
    "print(og['CountryName'].unique())\n",
    "\n",
    "og['CountryName'] = og['CountryName'].map({'United Kingdom': 'UK', 'United States': 'USA', 'France': 'France', 'Italy': 'Italy', 'India':'India', 'Germany':'Germany'})\n",
    "print(data['Demographics_COVID_Current Country'].unique())\n",
    "print(og['CountryName'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Oxford data to our table, based on date and country\n",
    "\n",
    "### Get col names from Oxford data\n",
    "# new_cols = og.columns.tolist()\n",
    "\n",
    "### Append OG so we can keep them straight\n",
    "# new_cols = ['OG_' + s for s in new_cols]\n",
    "\n",
    "### Add empty cols to our data frame\n",
    "# data = data.reindex(columns=data.columns.tolist() + new_cols) \n",
    "\n",
    "### rearrange columns to be in alphabetical order\n",
    "# data = data.reindex(sorted(data.columns), axis=1)\n",
    "\n",
    "### Merge data frames\n",
    "data = pd.merge(data, og,  how='left', left_on=['Demographics_COVID_Current Country','Survey Info_EndDate'], right_on = ['CountryName','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['Survey Info_EndDate'], format='%Y%m%d', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'ConfirmedCases':'Country_Confirmed Cases',\n",
    "                     'ConfirmedDeaths':'Country_Confirmed Deaths',\n",
    "                     'ContainmentHealthIndexForDisplay': 'Country_Containment Health Index',\n",
    "                     'EconomicSupportIndexForDisplay':'Country_Economic Support Index',\n",
    "                     'GovernmentResponseIndexForDisplay':'Country_Government Response Index',\n",
    "                     'StringencyIndexForDisplay':'Country_Stringency Index',\n",
    "                     'Demographics_COVID_Current Country':'Country_Country Name'\n",
    "                    }, \n",
    "            inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reindex(sorted(data.columns), axis=1)\n",
    "data['ID'] = data.index + 1\n",
    "id_col = data.pop('ID')\n",
    "data.insert(0, 'ID', id_col)\n",
    "data.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that we're not using\n",
    "drop_cols = [\n",
    "         'C1_School closing', 'C2_Workplace closing', 'C3_Cancel public events',\n",
    "         'C4_Restrictions on gatherings', 'C5_Close public transport', 'C6_Stay at home requirements',\n",
    "         'C7_Restrictions on internal movement', 'C8_International travel controls',\n",
    "         'ContainmentHealthIndex', \n",
    "         'CountryName', 'Date',\n",
    "         'Demographics_COVID_Current State', # only NYC\n",
    "         'Demographics_COVID_Profession', # free text\n",
    "         'Demographics_General_Years of Post-School', 'Demographics_General_Years of School', # combined in the 'Demographics_General_Education Years column'\n",
    "         'E1_Income support', 'E2_Debt/contract relief', 'E3_Fiscal measures', 'E4_International support',\n",
    "         'ESM_Self-Generated Code', \n",
    "         'EconomicSupportIndex', \n",
    "         'GovernmentResponseIndex', \n",
    "         'H1_Public information campaigns', 'H2_Testing policy', \n",
    "         'H3_Contact tracing', 'H4_Emergency investment in healthcare', 'H5_Investment in vaccines',\n",
    "         'ResponseId', \n",
    "         'StartDate', \n",
    "         'StringencyIndex', 'StringencyLegacyIndexForDisplay',\n",
    "         'Survey Info_EndDate', \n",
    "         'Survey Info_Progress', 'Survey Info_RecordedDate', 'Survey Info_Source'\n",
    "        ]\n",
    "\n",
    "data = data.drop(columns = drop_cols, axis = 1)\n",
    "data.reset_index(inplace = True, drop = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export quantitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5907, 239)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'raw_data.csv', index = None, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
